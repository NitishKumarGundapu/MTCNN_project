{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_faces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import warnings\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from numpy import load\n",
    "from os.path import isdir\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(160, 160)):\n",
    "\timage = Image.open(filename)\n",
    "\timage = image.convert('RGB')\n",
    "\tpixels = np.asarray(image)\n",
    "\tdetector = MTCNN()\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx1, y1 = abs(x1), abs(y1)\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = np.asarray(image)\n",
    "\treturn face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(directory):\n",
    "\tfaces = list()\n",
    "\tfor filename in listdir(directory):\n",
    "\t\tpath = directory + filename\n",
    "\t\tface = extract_face(path)\n",
    "\t\tfaces.append(face)\n",
    "\treturn faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "\tX, y = list(), list()\n",
    "\tfor subdir in listdir(directory):\n",
    "\t\tpath = directory + subdir + '/'\n",
    "\t\tif not isdir(path):\n",
    "\t\t\tcontinue\n",
    "\t\tfaces = load_faces(path)\n",
    "\t\tlabels = [subdir for _ in range(len(faces))]\n",
    "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "\t\tX.extend(faces)\n",
    "\t\ty.extend(labels)\n",
    "\treturn np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face1(filename, required_size=(160, 160)):\n",
    "\timage = Image.open(filename)\n",
    "\timage = image.convert('RGB')\n",
    "\tpixels = asarray(image)\n",
    "\tdetector = MTCNN()\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\tface_array1 = []\n",
    "\tfor a in range(len(results)):\n",
    "\t\tx1, y1, width, height = results[a]['box']\n",
    "\t\tx1, y1 = abs(x1), abs(y1)\n",
    "\t\tx2, y2 = x1 + width, y1 + height\n",
    "\t\tface = pixels[y1:y2, x1:x2]\n",
    "\t\tbox_faces.append([x1, y1, width, height])\n",
    "\t\timage = Image.fromarray(face)\n",
    "\t\timage = image.resize(required_size)\n",
    "\t\tface_array1.append(asarray(image))\n",
    "\treturn face_array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "\tface_pixels = face_pixels.astype('float32')\n",
    "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
    "\tface_pixels = (face_pixels - mean) / std\n",
    "\tsamples = np.expand_dims(face_pixels, axis=0)\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 21 examples for class: akshay_kumar\n",
      ">loaded 14 examples for class: amir_khan\n",
      ">loaded 18 examples for class: ben_afflek\n",
      ">loaded 21 examples for class: jerry_seinfeld\n",
      ">loaded 22 examples for class: john_elton\n",
      ">loaded 19 examples for class: madonna\n",
      ">loaded 22 examples for class: mindy_kaling\n",
      ">loaded 20 examples for class: rajini_kanth\n",
      "Loaded:  (157, 160, 160, 3) (157,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitish_kumar\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model\n",
      "(157, 128)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset(\"C:\\\\Users\\\\Nitish_kumar\\\\Desktop\\\\nice\\\\data\\\\train\\\\\")\n",
    "print('Loaded: ', trainX.shape, trainy.shape)\n",
    "model = load_model('facenet_keras.h5')\n",
    "print('Loaded Model')\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "\tembedding = get_embedding(model, face_pixels)\n",
    "\tnewTrainX.append(embedding)\n",
    "newTrainX = np.asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "np.savez_compressed('data.npz',newTrainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load(r'C:\\\\Users\\\\Nitish_kumar\\\\Desktop\\\\nice\\\\data.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitish_kumar\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ben_afflek (100.000)\n"
     ]
    }
   ],
   "source": [
    "model_face = load_model(r'C:\\\\Users\\\\Nitish_kumar\\\\Desktop\\\\nice\\\\facenet_keras.h5')\n",
    "\n",
    "image_path = 'data\\\\test\\\\a.jpg'\n",
    "\n",
    "for a in extract_face1(r'C:\\\\Users\\\\Nitish_kumar\\\\Desktop\\\\nice\\\\'+image_path):\n",
    "\ttest_image = get_embedding(model_face,a)\n",
    "\ttest_image = np.array([test_image])\n",
    "\ttest_image = in_encoder.transform(test_image)\n",
    "\n",
    "\tyhat_class = model.predict(test_image)\n",
    "\tyhat_prob = model.predict_proba(test_image)\n",
    "\n",
    "\tclass_index = yhat_class[0]\n",
    "\tclass_probability = yhat_prob[0,class_index] * 100\n",
    "\tpredict_names = out_encoder.inverse_transform(yhat_class)\n",
    "\tprint('Predicted: %s (%.3f)' % (predict_names[0], class_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(image_path)\n",
    "\n",
    "for a in box_faces:\n",
    "\tx, y, w, h = a\n",
    "\tcv2.rectangle(image, (x, y), (x + w, y + h), (255,0,0), 2)\n",
    "\ttext = \"%s (%.3f)\" % (predict_names[0], class_probability)\n",
    "\tcv2.putText(image, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.36, (255,0,0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
